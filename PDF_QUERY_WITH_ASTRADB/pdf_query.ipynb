{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a99c33",
   "metadata": {},
   "source": [
    "### Importing packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "771ec783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abirf\\OneDrive\\Desktop\\Projcts\\LangChain\\PDF_QUERY_WITH_ASTRADB\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#langchain components to use \n",
    "from langchain_community.vectorstores import Cassandra\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "#support for dataset retrieval with hugging face\n",
    "from datasets import load_dataset\n",
    "\n",
    "#with CassIO, the engine powering the Astra DB integration in Langchain\n",
    "#It helps to initialize the DB connection\n",
    "import cassio\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2cdff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65f4e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96a9787",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_reader = PdfReader('SlotFinder_A_Spatio-temporal_based_Car_Parking_System.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b06888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Concatenate\n",
    "#read text from pdf \n",
    "raw_text = ''\n",
    "for i, page in enumerate(pdf_reader.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        raw_text+=content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7977e460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022 25th International Conference on Computer and Information Technology (ICCIT)\\n17-19 December 2022, Cox’s Bazar, Bangladesh\\nSlotFinder: A Spatio-temporal based Car Parking\\nSystem\\nMebin Rahman Fateha, Md. Saddam Hossain Mukta, Md. Abir Hossain, Mahmud Al Islam, Salekul Islam\\nDepartment of CSE, United International University (UIU)\\nPlot-2, United City, Madani Avenue, Badda, Dhaka-1212, Bangladesh\\nEmail: mfateha171124@bscse.uiu.ac.bd, saddam@cse.uiu.ac.bd, mhossain171125@bscse.uiu.ac.bd,\\nmislam171131@bscse.uiu.ac.bd, salekul@cse.uiu.ac.bd\\nAbstract —Nowadays, the increasing number of vehicles and\\nshortage of parking spaces have become an inescapable condition\\nin big cities across the world. Car parking problem is not a\\nnew phenomenon, especially in a crowded city such as Dhaka,\\nBangladesh. Shortage of parking spaces leads to several problems\\nsuch as road congestion, illegal parking on the streets, and fuel\\nwaste in searching for a free parking space. In order to overcome\\nthe parking problem, we develop a spatio-temporal based car\\nparking system namely, SlotFinder . We collect the data of 408\\nbuildings those have parking slots from seven different locations.\\nWe then cluster these data based on time and locations. Later, we\\ntrain location wise vacant parking spaces by using stacked Long\\nShort-Term Memory (LSTM) based on their temporal patterns.\\nWe also compare our technique with the baseline models and\\nconduct an ablation analysis, which outperforms (lower RMSE\\nand MAE of 0.29 and 0.24, respectively) than that of the previous\\napproaches.\\nIndex Terms —Stacked LSTM, Spatio-temporal, Car parking\\nsystem, Machine Learning\\nI. I NTRODUCTION\\nCar parking is an emerging problem with the increasing\\nnumber of vehicles in large cities world wide. Dhaka city is\\nan unplanned city where roads, housing and offices are estab-\\nlished without foreseeing the inconvenient future. Therefore,\\nfinding a parking space is a common problem created by the\\nincreased number of vehicles. Searching for a parking space\\nrequires time, effort and extra fuel. A global parking survey\\nby IBM in 2011 shows that 20 minutes is spent on average in\\nsearching for a perfect parking space [7]. To solve the problem,\\nwe develop a spatio-temporal based car parking model, namely\\nSlotFinder .\\nDhaka city is one of the most densely populated areas in\\nthe world. In 2010, the population of Dhaka city was 14.7\\nmillion and in 2021, it became 21.7 million, which reflects\\na significant increase of population from 2010 to 2021 [3].\\nWith the increasing number of population, the number of\\nregistered vehicles is also rising proportionally. Parking poses\\na serious challenge to the vehicle owners since there is a\\nserious shortage of parking facilities. The parking problem\\nleads to illegal parking on city streets, increasing intense traffic\\njam and worsening the annoyance of the moving traffic. Thus,\\nthe overall parking problem has motivated us to come up\\nwith a solution. Towards this direction, we develop a machine\\nlearning based spatio-temporal car parking system. We findseveral location aware applications in the literature [6], [11],\\n[12], [14], [15], which largely apply RNN models to predict\\nin terms of both space and time.\\nIn this study, we collect data from 408 buildings from seven\\ndifferent areas of Dhaka city. Our dataset contains six spatio-\\ntemporal features. First, we apply k-Means clustering based\\non longitude and latitude to group up the regions with similar\\nparking trend. Then, we use the clustering technique with\\nk=7 to make seven clusters and each cluster consists of time\\nintervals of vacant parking spaces in a region. Then, to learn\\nour model the pattern of the parking vacancies, we apply RNN\\nbased stacked LSTM model on each cluster to predict vacant\\nparking spaces (departure and arrival time).\\nIn short, in this paper, we have following contribution:\\n•We build a dataset with available car parking time (i.e,\\ndeparture and arrival time) and spatial features (i.e.,\\nlatitude and longitude).\\n•We develop an efficient spatio-temporal based stacked\\nLSTM for predicting the vacant parking spaces.\\n•We demonstrate that our model outperforms the baseline\\napproaches.\\nII. L ITERATURE REVIEW\\nIn this section, we present several studies related to car\\nparking systems. Kotb et al. [5] introduced a smart car parking\\nsystem with static resource scheduling, dynamic resource\\nallocation and pricing models, to optimize the parking system\\nfor drivers and parking owners. They combined real time\\nreservation (RTR) with share time reservation (STR).\\nGandhi et al. [4] introduced a system that directs informa-\\ntion about open and full parking spaces via mobile or web\\napplication. This IoT system includes micro-controller and\\nsensor devices with Electric Vehicle (EV)–charging points,\\nwhich is situated in respective car parking space. Zacepins\\net al. [21] proposed a smart parking management based on\\nvideo processing and analysis. In this paper they made a\\npython application for real time parking lot monitoring. For\\nthe occupancy detection in parking, they used five classifiers\\n(Logistic Regression, Linear Support Vector Machine, Radial\\nBasis Function Support Vector Machine, Decision Tree and\\nRandom Forest). Shao et al. [17] introduced a range based\\nkNN algorithm which is named as Range-kNN. Their proposed\\n979-8-3503-4602-2/22/$31.00 ©2022 IEEE\\nPage 1142022 25th International Conference on Computer and Information Technology (ICCIT) | 979-8-3503-4602-2/22/$31.00 ©2022 IEEE | DOI: 10.1109/ICCIT57492.2022.10055168\\nAuthorized licensed use limited to: UNIVERSITY OF BIRMINGHAM. Downloaded on February 24,2024 at 19:12:04 UTC from IEEE Xplore.  Restrictions apply. Fig. 1. Methodology of spatio-temporal based car parking system.\\nalgorithm consists of two parts: expansion of query range and\\nsearch algorithm.\\nWe observe that the majority of the studies consider spaces\\nonly where temporal parameters are not taken in consideration\\nwhile time is a vital factor. Towards this direction, we propose\\na novel stacked LSTM based car parking solution which\\nconsiders both space and time.\\nIII. M ETHODOLOGY\\nIn this paper, we mainly work with spatial-temporal dataset.\\nFigure 1 shows different steps of our proposed car parking sys-\\ntem. First, we select a location which is ideally a crowded area\\nand where most of the people have their own vehicles. Then,\\nwe annotate these areas with starting and departure times.\\nLater, we find different pattern for the starting and departure\\ntimes based on locations. By observing these patterns, we\\napply our spatio-temporal based machine learning technique.\\nWe briefly present the pipelines of our study.\\nA. Data Collection\\nIn this section, we first select seven populated areas in\\nDhaka city for collecting data. In these areas, people have\\nhigher percentage (around 45%) [18] of their own vehicles.\\nTABLE I\\nSUMMARY OF COLLECTED DATA .\\nDimension 408x6\\nNumber of areas 7\\nAverage\\ndeparture time8:00 AM - 9:00 AM\\nAverage\\narrival time5:00 PM - 6:00 PM\\nDuration of\\nempty parking9-10 hours\\nAverage number of\\nempty parking5-10\\nAverage parking\\nspaces20-25\\nNumber of\\ninstances408We also choose those areas where parking problem is a\\ncommon issue due to the increased crowd and less parking\\nfacilities. After area selection, the next step is to annotate\\nthe buildings to identify the parking spaces by its latitude\\nand longitude. For collecting data, we conduct field visits in\\nseven locations inside Dhaka such as Dhanmondi, Gulshan,\\nUttara, Mirpur, etc.1. We visit several residential buildings in\\norder to get the parking information. We take some relevant\\ninformation about parking spaces such as if there is any free\\nparking space, for how much time in a day it remains vacant,\\nwhether a specific parking space remains occupied and free,\\netc. We take these information from 408 buildings of seven\\nareas by taking face-to-face survey with building managers.\\nA summary of collected data is shown in Table I. Frequent\\ndeparture time of vacant parking spaces is 8:00 am to 9:00 am\\nand arrival time is 5:00 pm to 6:00 pm. Average duration of\\nthe vacant parking spaces is 9-10 hours. Each building has 5-\\n10 vacant parking spaces on an average. However, for further\\nresearch, we share the dataset for public use2. Table II shows\\nthe number of instances from each area based on average\\ndeparture and arrival time.\\nTABLE II\\nNUMBER OF INSTANCES PER AREA BASED ON THEIR AVERAGE\\nDEPARTURE AND ARRIVAL TIME .\\nArea Name Departure time Arrival time size\\nDhanmondi 8:00 AM - 9:00 AM 5:00 PM - 6:00 PM 74\\nGulshan 9:00 AM - 10:00 AM 5:00 PM - 6:00 PM 67\\nUttara 8:00 AM - 9:00 AM 6:00 PM - 7:00 PM 63\\nMirpur 7:00 AM - 8:00 AM 5:00 PM - 6:00 PM 71\\nKallyanpur 7:00 AM - 8:00 AM 5:00 PM - 6:00 PM 48\\nShyamoli 8:00 AM - 9:00 AM 5:00 PM - 6:00 PM 42\\nMohammadpur 8:00 AM - 9:00 AM 5:00 PM - 6:00 PM 43\\nTotal 408\\n1Google map: shorturl.at/lruTZ\\n2https://bit.ly/3yiNvFY\\nPage 115\\nAuthorized licensed use limited to: UNIVERSITY OF BIRMINGHAM. Downloaded on February 24,2024 at 19:12:04 UTC from IEEE Xplore.  Restrictions apply. Fig. 2. Architecture of our SlotFinder System.\\nB. Building Model\\nIn this section, we first describe our system architecture in\\nFigure 2. Then, we present our clustering approach and discuss\\ndata preparation techniques. Next, we discuss how we apply\\nour proposed stacked LSTM model over our dataset.\\nWe take the parking information based on the time interval\\nwhether a parking space is vacant and store these information\\nin the data set. After that, we apply k-Means clustering on the\\ndata set based on location. The availability of free parking\\nspace with time is different for each areas in Dhaka city.\\nDuring our field study, we see some significant differences\\nin parking trends among the seven areas. For example, the\\naverage departure time for Dhanmondi area is 8:00-9:00 AM\\nand for Gulshan the average departure time is 9:00-10:00 AM.\\nSince Dhanmondi has become the biggest hub of educational\\ninstitutes and the majority of the schools start lectures around\\n8:00-8:30 AM. Therefore, the maximum parking spaces of\\nthis area get vacant around 8:00-9:00 AM. On the other hand,\\nmany private corporations start their offices in Gulshan and the\\nmaximum people who live in Gulshan has office or business\\naround Gulshan. Thus, they leave their home around 9:00-\\n10:00 AM . Before applying our machine learning algorithm,\\nwe group similar parking spaces together. Therefore, we apply\\nk-Means clustering method with k=7 as we collect data from\\nseven different areas to group 408 parking spaces. We use\\nlongitude and latitude values of each parking space as input\\nfeature for the clustering. Figure 3 shows seven clusters with\\nrespect to cluster centroids.\\nData preparation is important because we prepare data\\nfor applying machine learning algorithms over a structured\\ndataset. Data preparation helps to find efficient result with\\nless error. Both numerical and categorical features are present\\nin our dataset. The categorical data cannot be immediately\\ninterpreted by machines. In order to process the categorical\\ndata further, we transform it into numerical data. In our dataset,\\ndeparture time and arrival time are in categorical form. We use\\nlabel encoding to convert these two features into numerical\\nform shown in Figure 4.\\nFig. 3. Clusters visualization based on latitude and longitude.\\nFig. 4. Label encoding of departure time and arrival time.\\nData scaling is a data preprocessing technique for numerical\\nfeatures. Data scaling is necessary for obtaining improved\\nperformance of many machine learning algorithms, including\\nRNN. For this, various scaling are defined. We use Min-\\nMax [13] scaling to scale our numerical features (range is\\n0 to 1).\\nThen, we split our dataset into train and test parts by 65%\\nand 35%, respectively. We train our dataset by using 10-\\niterations with 10-fold cross validation. Parking event main-\\ntains a sequence and we also observe that the buildings in a\\nspecific region maintain a sequence of similar parking trend.\\nFor this reason, we apply stacked LSTM in each cluster that\\npredicts departure time and arrival time. The basic LSTM\\nmodel consists of a single hidden LSTM layer followed by a\\nPage 116\\nAuthorized licensed use limited to: UNIVERSITY OF BIRMINGHAM. Downloaded on February 24,2024 at 19:12:04 UTC from IEEE Xplore.  Restrictions apply. Fig. 5. Re-arranging of trainX and trainY .\\nconventional feedforward output layer. The Stacked LSTM is\\na model extension that contains multiple hidden LSTM layers,\\neach of which contains multiple memory cells [8], [16]. Since\\nour desired output predicts both the departure and arrival time,\\ntherefore we incorporate the stacked LSTM in our problem.\\nOur stacked LSTM model consists of several LSTM layers.\\nIn stacked LSTM architecture, the output of the first LSTM\\nlayer goes as input of the next LSTM layer. In our model,\\nthe first LSTM has 64 layers and the second LSTM has 32\\nlayers. We use a dropout of 0.2 followed by a dense layer.\\nIn our experiment, we consider time steps to be 3, time steps\\ndenote that how previous data should be considered to predict\\nthe future parking time. Considering the time steps to be 3\\ngives us an optimal result. We take previous 3 parking times\\nto predict the 4th parking timing. We split the data as X, Y .\\nIn the 0-th iteration, the first 3 values are in X and the 4th\\nvalue is in Y and so on as shown in Figure 5. In this manner,\\nwe re-arrange both our train and test datasets. Figure 6 (a)\\nshows the training loss and validation loss of a single cluster\\nand Figure 6 (b) shows the training loss and validation loss of\\nthe seven clusters. We see from the figures that the training\\nloss and validation loss both decrease and remain stable at a\\npoint.\\nFig. 6. Training Loss and Validation Loss.\\nC. Ablation Study\\nComponents of a deep learning network are typically\\ndeleted or replaced as part of an experiment called an ablation\\nstudy to determine how these changes affect the overallperformance of the system. The performance of a model may\\nremain stable, become better or get worse when these com-\\nponents are changed. Accuracy can be improved primarily by\\nexperimenting with various hyper-parameters like optimizer,\\nlearning rates, loss functions and batch sizes. Altering the\\narchitecture of the model has an effect on overall performance.\\nIn this study, we demonstrate six case studies by altering\\ndifferent system parameters and response of the system by\\nthe changes.\\nEvaluation Metrics: We apply three metrics to evaluate our\\nproposed model: mean absolute error (MAE), mean squared\\nerror (MSE) and root mean squared error (RMSE). Six ex-\\nperiments are conducted as an ablation study, each changing a\\ndifferent components of the proposed Stacked LSTM model. A\\nmore reliable architecture with improved performance can be\\nachieved by changing many components. This is accomplished\\nby performing an ablation study on a number of components:\\nbatch size, hidden layer, loss function, optimizer, learning rate,\\nactivation function and dropout.\\n1) Ablation Study 1 (Changing Hidden Layers): In our\\nmodel, we use stacked LSTM. In this stacked LSTM we have\\n2 LSTM layers. In the first LSTM, we have 64 hidden layers\\nand in the second LSTM, we have 32 hidden layers. To observe\\nthe model’s performance we change the number of the hidden\\nlayers of both the LSTMs. In Table III, we present RMSE,\\nMAE and Val loss scores in Table III.\\nTABLE III\\nABLATION STUDY BY CHANGING THE HIDDEN LAYERS .\\nCase StudyHidden\\nlyerRMSE MAE Val Loss\\n1LSTM1-64\\nLSTM2- 320.30 0.25 0.03\\nLSTM1- 128\\nLSTM2- 640.30 0.25 0.01\\nLSTM1- 50\\nLSTM2- 500.30 0.25 0.02\\n2) Ablation Study 2 (Changing Batch Size): The term\\n“batch size” refers to the number of training samples used\\nin a single iteration. To determine the ideal batch size for our\\nproposed model, we experiment with different batch sizes in\\nour study. When we change our bacth size from 64 to 16\\nwhich gives RMSE from 0.3 to 0.29. The results are shown\\nin Table IV.\\nTABLE IV\\nABLATION STUDY BY CHANGING THE BATCH SIZE .\\nCase Study Batch Size RMSE MAE Val Loss\\n2 16 0.29 0.25 0.01\\n32 0.30 0.26 0.03\\n64 0.30 0.25 0.01\\n3) Ablation Study 3 (Changing Optimizer): We use\\nAdam [22] in our model as optimizer. The model gives us\\nRMSE, MAE and Val loss scores of 0.29, 0.25 and 0.01,\\nrespectively. If we change the optimizer to sgd and Nadam\\nwhich give us an increase in the scores of RMSE, MAE\\nPage 117\\nAuthorized licensed use limited to: UNIVERSITY OF BIRMINGHAM. Downloaded on February 24,2024 at 19:12:04 UTC from IEEE Xplore.  Restrictions apply. and Val loss shown in Table V. SGD does each iteration\\nusing a single sample, or a batch size of one. The sample\\nis chosen and randomly shuffled in order to carry out the\\niteration. Nadam [19] is an optimizer combination of adam\\nand RMSprop with Nesterov momentum.\\nTABLE V\\nABLATION STUDY BY CHANGING OPTIMIZER .\\nCase Study Optimizer RMSE MAE Val Loss\\n3 sgd 0.35 0.31 0.04\\nadam 0.29 0.25 0.01\\nnadam 0.30 0.25 0.01\\n4) Ablation Study 4 (Changing Learning Rate): We use\\nlearning rate of 0.01 which gives RMSE, MAE and Val loss\\nscores of 0.29, 0.24 and 0.01, respectively. If we replace the\\nlearning rate with 0.001 and 0.0001, the scores of RMSE,\\nMAE and Val loss increase. The results are shown in Table VI.\\nTABLE VI\\nABLATION STUDY BY CHANGING LEARNING RATES .\\nCase StudyLearning\\nRateRMSE MAE Val Loss\\n4 0.01 0.29 0.24 0.01\\n0.001 0.30 0.24 0.03\\n0.0001 0.57 0.50 0.04\\n5) Ablation Study 5 (Changing Activation Functions):\\nWe use activation function of ReLU initially. It gives RMSE\\nof 0.294 and MAE of 0.246. After replacing the activation\\nfunction with softmax gives RMSE of 0.290 and MAE of\\n0.242. We also replace the activation function with tanh. The\\nresults are shown in Table VII.\\nTABLE VII\\nABLATION STUDY BY CHANGING ACTIVATION FUNCTION .\\nCase StudyActivation\\nFunctionRMSE MAE Val Loss\\n5 reLU 0.294 0.246 0.01\\nsoftmax 0.290 0.242 0.01\\ntanh 0.292 0.245 0.01\\n6) Ablation Study 6 (Changing Dropout): We also use\\ndropout of 0.2 which gives RMSE and MAE scores of 0.290\\nand 0.242, respectively. We apply dropouts of 0.5 and 0.7 as\\nwell. The results are shown in Table VIII.\\nTABLE VIII\\nABLATION STUDY BY CHANGING THE DROPOUTS .\\nCase Study Dropout RMSE MAE Val Loss\\n6 0.2 0.290 0.242 0.01\\n0.5 0.291 0.243 0.02\\n0.7 0.291 0.243 0.01\\nD. Performance Analysis of the Best Model\\nAfter analyzing all the case studies, we set a model with\\nlower error rate when the optimal batch size, learning rate,optimizer and number of hidden layers are used. Table IX\\nshows the final configuration of our stacked LSTM model for\\npredicting vacant car parking slots in different regions.\\nTABLE IX\\nCONFIGURATION OF PROPOSED ARCHITECTURE AFTER ABLATION STUDY .\\nConfiguration Value\\nData set size 408×6\\nEpochs 100\\nOptimization\\nfunctionAdam\\nLearning rate 0.01\\nBatch size 16\\nActivation\\nfunctionSoftmax\\nDropout 0.2\\nIV. C OMPARISON WITH BASELINE MODELS\\nWe also apply Recurrent Neural Network (RNN) [20],\\nAutoregressive integrated moving average (ARIMA) [2] and\\nLSTM [23] models to predict vacant car parking time as\\nbaseline models. However, in this case, out stacked LSTM\\nmodel outperforms than that of the mentioned models. Table X\\nshows the performance of different baseline models including\\nour proposed stacked LSTM model.\\nTABLE X\\nPERFORMANCE OF DIFFERENT MODELS\\nModels RMSE MAE Val Loss\\nLSTM 0.35 0.35 0.04\\nRNN 0.45 0.48 0.03\\nARIMA 0.40 0.30 0.04\\nStacked LSTM 0.29 0.25 0.01\\nV. R ESULTS AND DISCUSSION\\nWe develop an efficient spatio-temporal based machine\\nlearning model for predicting vacant parking spaces. First, we\\napply a clustering method based on their location to group\\nup the regions with similar parking trends. Later, we apply\\nstacked LSTM to predict departure and arrival time of vacant\\nparking spaces.\\nDuring data collection, we observe that different regions\\nfollow different parking trends. We see that the departure\\nand arrival times of every area maintain a particular pattern.\\nThus, we apply stacked LSTM in each cluster that predicts\\ndeparture and arrival times. The basic LSTM model consists\\nof a single hidden LSTM layer followed by a conventional\\nfeedforward output layer. The Stacked LSTM is a model\\nextension that contains multiple hidden LSTM layers, each\\nof which contains multiple memory cells. Since our desired\\noutput predicts both the departure and arrival time, therefore\\nwe incorporate the stacked LSTM in our problem. Our stacked\\nLSTM model consists of several LSTM layers. In stacked\\nLSTM architecture, the output of the first LSTM layer goes\\nas input of the next LSTM layer. In our model the first LSTM\\nhas 128 layers and the second LSTM has 64 layers. We use a\\ndropout of 0.2 followed by a dense layer. Our ablation study\\nPage 118\\nAuthorized licensed use limited to: UNIVERSITY OF BIRMINGHAM. Downloaded on February 24,2024 at 19:12:04 UTC from IEEE Xplore.  Restrictions apply. finds the best configuration for our model. For the hidden layer,\\nwe use 128 hidden layers for the first LSTM and 64 for the\\nsecond LSTM. We apply batch sizes of 64, 32 and 16. Batch\\nsize of 16 gives us the lower RMSE and MAE. We changed\\nour activation function with reLU, softmax and tanh. Softmax\\nperforms better than the other activation functions. Initially,\\nwe apply adam optimizer then we also apply sgd and nadam\\nbut adam gives the optimal result. We stick with the initial\\nlearning rate which is 0.01 because after changing the learning\\nrate with 0.001 and 0.0001, we find an increased RMSE and\\nMAE scores. Lastly, we find changing the dropout values with\\n0.2 which gives the optimal result.\\nWe consider applying RNN in our model, but we work with\\nonly 408 buildings for now but in reality there are thousands\\nof buildings. In that case, RNN does not give optimal results\\nbecause it has a long term dependency problem due to the\\nvanishing gradient problem. LSTM overcomes the long term\\ndependency problem. After training the model, the prediction\\nfor Dhanmondi, Gulshan and Mirpur clusters perform better\\nthan the rest of the clusters because the number of instances\\nin Gulshan, Dhanmondi and Mirpur is large compared to\\nother clusters. A few studies [1], [9], [10] show that weighted\\nLSTM and HMM models also provide satisfactory results\\nin predicting future events. However, our model has several\\nlimitations which can be an avenue for future research. Our\\nmodel cannot find the nearest parking spaces and needs the\\nlongitude and latitude values of a specific building to predict\\nvacant parking space.\\nThe parking behavior of people might sound unrealistic as if\\nthey are robotic entities. However, we observe similar patterns\\nof the parking behavior because the office time is generally\\n9:00 AM to 5:00 PM and the time of the educational institutes\\nis mostly 8:00 AM to 4:00 PM. In addition to this, we mainly\\nwork with departure and arrival time. For this reason, we do\\nnot consider any spatial and managerial factors. Therefore,\\nwe do not need to apply any nearest neighbor or distance\\nsearching algorithms by using spatial data structures.\\nVI. C ONCLUSION\\nIn this paper, we have worked with real world spatio-\\ntemporal dataset to predict free parking time (departure time\\nand arrival time). First, we have applied clustering method\\nwhere k=7 in seven different locations (longitude and latitude)\\nto group up the regions with similar parking trend. Later,\\nwe have applied stacked LSTM on each cluster to predict\\ndeparture and arrival time of those parking spaces. We have\\ntrained with stacked LSTM to predict vacant parking spaces\\nin a region. We have conducted an ablation study to see the\\nimpact of the components within the architecture and to select\\nthe optimal values of the components. We have also compared\\nour techniques with the baseline techniques and found that our\\nsystem outperforms than that of the previous approaches.\\nREFERENCES\\n[1] Al Rafi, A.S., Rahman, T., Al Abir, A.R., Rajib, T.A., Islam, M., Mukta,\\nM.S.H.: A new classification technique: random weighted lstm (rwl). In:2020 IEEE Region 10 Symposium (TENSYMP). pp. 262–265. IEEE\\n(2020)\\n[2] Benvenuto, D., Giovanetti, M., Vassallo, L., Angeletti, S., Ciccozzi, M.:\\nApplication of the arima model on the covid-2019 epidemic dataset.\\nData in brief 29, 105340 (2020)\\n[3] BRTA: Number of registered motor vehicles in bangladesh (yearwise)\\nRetrieved from. shorturl.at/kqD78 (July 7, 2020)\\n[4] Gandhi, R., Nagarajan, S., Chandramohan, J., Parimala, A., Arulmu-\\nrugan, V .: Iot based automatic smart parking system with ev-charging\\npoint in crowd sensing area. Annals of the Romanian Society for Cell\\nBiology 25(6), 6398–6409 (2021)\\n[5] Kotb, A.O., Shen, Y .C., Zhu, X., Huang, Y .: iparker—a new smart\\ncar-parking system based on dynamic resource allocation and pricing.\\nIEEE transactions on intelligent transportation systems 17(9), 2637–\\n2647 (2016)\\n[6] Leon, M.I., Iqbal, M.I., Meem, S., Alahi, F., Ahmed, M., Shatabda, S.,\\nMukta, M.S.H.: Dengue outbreak prediction from weather aware data.\\nIn: International Conference on Bangabandhu and Digital Bangladesh.\\npp. 1–11. Springer (2022)\\n[7] Liang, J.K., Eccarius, T., Lu, C.C.: Investigating factors that affect the\\nintention to use shared parking: A case study of taipei city. Transporta-\\ntion Research Part A: Policy and Practice 130, 799–812 (2019)\\n[8] Malhotra, P., Vig, L., Shroff, G., Agarwal, P., et al.: Long short term\\nmemory networks for anomaly detection in time series. In: Proceedings.\\nvol. 89, pp. 89–94 (2015)\\n[9] Mukta, M.S.H., Ali, M.E., Mahmud, J.: Identifying and predicting\\ntemporal change of basic human values from social network usage.\\nIn: Proceedings of the 2017 IEEE/ACM International Conference on\\nAdvances in Social Networks Analysis and Mining 2017. pp. 619–620\\n(2017)\\n[10] Mukta, M.S.H., Ali, M.E., Mahmud, J.: Temporal modeling of basic\\nhuman values from social network usage. Journal of the Association for\\nInformation Science and Technology 70(2), 151–163 (2019)\\n[11] Nawshin, S., Mukta, M.S.H., Ali, M.E., Islam, A.N.: Modeling weather-\\naware prediction of user activities and future visits. IEEE Access 8,\\n105127–105138 (2020)\\n[12] Rahman, M.M., Majumder, M.T.H., Mukta, M.S.H., Ali, M.E., Mahmud,\\nJ.: Can we predict eat-out preference of a person from tweets? In:\\nProceedings of the 8th ACM Conference on Web Science. pp. 350–351\\n(2016)\\n[13] Raju, V .G., Lakshmi, K.P., Jain, V .M., Kalidindi, A., Padma, V .: Study\\nthe influence of normalization/transformation process on the accuracy\\nof supervised classification. In: ICSSIT. pp. 729–735. IEEE (2020)\\n[14] Riad, S., Ahmed, M., Himel, M.H., Mim, A.H., Zaman, A., Islam,\\nS., Mukta, M.S.H.: Prediction of soil nutrients using hyperspectral\\nsatellite imaging. In: Proceedings of International Conference on Fourth\\nIndustrial Revolution and Beyond 2021. pp. 183–198. Springer (2022)\\n[15] Rupai, A.A.A., Mukta, M.S.H., Islam, A.N.: Predicting bowling perfor-\\nmance in cricket from publicly available data. In: Proceedings of the\\nInternational Conference on Computing Advancements. pp. 1–6 (2020)\\n[16] Sagheer, A., Kotb, M.: Unsupervised pre-training of a deep lstm-based\\nstacked autoencoder for multivariate time series forecasting problems.\\nScientific reports 9(1), 1–16 (2019)\\n[17] Shao, Z., Taniar, D.: Range-based nearest neighbour search in a mobile\\nenvironment. In: Proceedings of the 12th International Conference on\\nAdvances in Mobile Computing and Multimedia. pp. 215–224 (2014)\\n[18] Sharmeen, N., Houston, D.: Urban form, socio-demographics, attitude\\nand activity spaces: Using household-based travel diary approach to\\nunderstand travel and activity space behaviors. Urban Science 4(4), 69\\n(2020)\\n[19] Tato, A., Nkambou, R.: Improving adam optimizer (2018)\\n[20] Tomasiello, S., Loia, V ., Khaliq, A.: A granular recurrent neural network\\nfor multiple time series prediction. Neural Computing and Applications\\n33(16), 10293–10310 (2021)\\n[21] Zacepins, A., Komasilovs, V ., Kviesis, A.: Implementation of smart\\nparking solution by image analysis. In: VEHITS. pp. 666–669 (2018)\\n[22] Zhang, Z.: Improved adam optimizer for deep neural networks. In:\\n2018 IEEE/ACM 26th International Symposium on Quality of Service\\n(IWQoS). pp. 1–2. Ieee (2018)\\n[23] Zhao, Z., Chen, W., Wu, X., Chen, P.C., Liu, J.: Lstm network: a\\ndeep learning approach for short-term traffic forecast. IET Intelligent\\nTransport Systems 11(2), 68–75 (2017)\\nPage 119\\nAuthorized licensed use limited to: UNIVERSITY OF BIRMINGHAM. Downloaded on February 24,2024 at 19:12:04 UTC from IEEE Xplore.  Restrictions apply. '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb9bd4e",
   "metadata": {},
   "source": [
    "### Initialize the connection to my Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bce0cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cassio.init(\n",
    "    token= os.environ['ASTRA_DB_APPLICATION_TOKEN'],\n",
    "    database_id= os.environ['ASTRA_DB_ID']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7eb408",
   "metadata": {},
   "source": [
    "### Creating the Langchain embedding and LLM object for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2188d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key= os.environ['OPENAI_API_KEY'],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.6\n",
    ")\n",
    "embedding = OpenAIEmbeddings(\n",
    "    api_key=os.environ['OPENAI_API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496aeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf98f4cc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
