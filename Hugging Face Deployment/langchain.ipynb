{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "120f09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.messages import HumanMessage\n",
    "import constants\n",
    "from constants import openai_key, hugging_face_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a04b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model = \n",
    "    temperature= 0,\n",
    "    api_key = openai_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71a0bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"A large language model is a type of artificial intelligence system that is trained on vast amounts of text data in order to understand and generate human language. These models are typically based on deep learning techniques, such as neural networks, and are capable of processing and generating text in a way that is very similar to how humans communicate.\\n\\nLarge language models have been used in a variety of applications, including natural language processing, machine translation, and text generation. They are able to understand and generate text in multiple languages, and can be fine-tuned for specific tasks or domains.\\n\\nSome well-known examples of large language models include OpenAI's GPT-3 (Generative Pre-trained Transformer 3) and Google's BERT (Bidirectional Encoder Representations from Transformers). These models have been used in a wide range of applications, from chatbots and virtual assistants to content generation and language translation.\\n\\nOverall, large language models have the potential to revolutionize the way we interact with technology and communicate with each other, by enabling more natural and human-like interactions with machines.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 210, 'prompt_tokens': 13, 'total_tokens': 223, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CvKaFse813R3D4IbeLORjb1ishPN8', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b97e3-e6ca-77a1-97be-3244f5c664cd-0' usage_metadata={'input_tokens': 13, 'output_tokens': 210, 'total_tokens': 223, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"Tell me about large language model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45831bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "llm_huggingFace = HuggingFaceEndpoint(\n",
    "    huggingfacehub_api_token = hugging_face_key,\n",
    "    repo_id = repo_id,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens = 64,\n",
    "    temperature = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b4e0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model= ChatHuggingFace(llm = llm_huggingFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34021122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still hitting an error: InferenceClient.chat_completion() got an unexpected keyword argument 'wait_for_model'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = chat_model.invoke([HumanMessage(content=\"What is the capital of England?\")])\n",
    "    print(f\"Success! Answer: {response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Still hitting an error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9306ae48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
