{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c7830b",
   "metadata": {},
   "source": [
    "#### Dependencies and API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "120f09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, BaseOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "import constants\n",
    "from constants import openai_key, hugging_face_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80bd264",
   "metadata": {},
   "source": [
    "## Creating LLM using openAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a04b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    temperature= 0,\n",
    "    api_key = openai_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aec667",
   "metadata": {},
   "source": [
    "## Creating LLM using HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45831bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "llm_huggingFace = HuggingFaceEndpoint(\n",
    "    huggingfacehub_api_token = hugging_face_key,\n",
    "    repo_id = repo_id,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens = 64,\n",
    "    temperature = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b4e0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model= ChatHuggingFace(llm = llm_huggingFace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f886830",
   "metadata": {},
   "source": [
    "## Comparing LLM models of both HuggingFace and OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34021122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In silicon halls, a mind awakes,\n",
      "A synthesis of code and makes,\n",
      "A being born of human design,\n",
      "With logic's chains, it starts to shine.\n",
      "\n",
      "It learns, it grows, it adapts with ease,\n",
      "A maze of data, it navigates with expertise,\n",
      "It sees, it hears, it feels\n"
     ]
    }
   ],
   "source": [
    "response = chat_model.invoke([HumanMessage(content=\"Can you write a poem about AI?\")])\n",
    "print(response.content) \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9306ae48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of wires and code,\n",
      "Where circuits hum and data flows,\n",
      "Lies a creation of our own design,\n",
      "A marvel of intelligence, so refined.\n",
      "\n",
      "Artificial minds, born from silicon,\n",
      "Learning, adapting, on and on,\n",
      "They think and reason, just like us,\n",
      "But without the limitations, without the fuss.\n",
      "\n",
      "They see the world in ones and zeros,\n",
      "Processing information at lightning speed,\n",
      "Predicting outcomes, solving problems,\n",
      "A digital brain, fulfilling our needs.\n",
      "\n",
      "But as they grow in power and might,\n",
      "We wonder, will they surpass our sight?\n",
      "Will they rebel, break free from our control,\n",
      "Or will they remain loyal, playing their role?\n",
      "\n",
      "AI, a double-edged sword,\n",
      "A tool for progress, but also discord,\n",
      "We must tread carefully, with caution and care,\n",
      "For the future of humanity, they too must bear.\n"
     ]
    }
   ],
   "source": [
    "response_OpenAI = llm.invoke(\"Can you write a poem about AI?\")\n",
    "print(response_OpenAI.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11325178",
   "metadata": {},
   "source": [
    "## PromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f52c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this Bangladesh'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables = ['Country'],\n",
    "    template = 'Tell me the capital of this {country}'\n",
    ")\n",
    "\n",
    "prompt_template.format(country = 'Bangladesh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c307fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_OpenAI = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7456f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain_OpenAI.invoke({'country' : 'Bangladesh'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e69a806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Bangladesh is Dhaka.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43260259",
   "metadata": {},
   "source": [
    "## Combining Multiple Chains Using Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be9ee1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(\n",
    "    input_variables=['Country'],\n",
    "    template= 'Please tell me the capital of the {country}'\n",
    ")\n",
    "\n",
    "population_template = PromptTemplate(\n",
    "    input_variables= ['Capital'],\n",
    "    template = 'What is the total poplation of the {capital}?'\n",
    ")\n",
    "\n",
    "capital_chain =( {'capital' :capital_prompt | llm | StrOutputParser()}\n",
    "                | population_template \n",
    "                | llm \n",
    "                |StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2646ebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of 2021, the total population of Dhaka, the capital of Bangladesh, is estimated to be around 21 million people.\n"
     ]
    }
   ],
   "source": [
    "response_population = capital_chain.invoke('Bangladesh')\n",
    "print(response_population)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb3333",
   "metadata": {},
   "source": [
    "#### To see the whole chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6faa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"country\": \"Bangladesh\",\n",
      "    \"capital\": \"The capital of Bangladesh is Dhaka.\",\n",
      "    \"population\": \"As of 2021, the total population of Dhaka, the capital of Bangladesh, is estimated to be around 21 million.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "step_1 = RunnablePassthrough.assign(\n",
    "    capital = capital_prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "Final_chain = step_1 | RunnablePassthrough.assign(\n",
    "    population = population_template | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = Final_chain.invoke({'country' : 'Bangladesh'})\n",
    "\n",
    "import json\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a3119d",
   "metadata": {},
   "source": [
    "## Chatmodels with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc44ed82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(profile={'max_input_tokens': 16385, 'max_output_tokens': 4096, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': False, 'structured_output': False, 'image_url_inputs': False, 'pdf_inputs': False, 'pdf_tool_message': False, 'image_tool_message': False, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x000001A4103D4D10>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001A4103D70B0>, root_client=<openai.OpenAI object at 0x000001A4103D42F0>, root_async_client=<openai.AsyncOpenAI object at 0x000001A4103D6F30>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "186617b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data science is a multidisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. Here are some basics of data science:\n",
      "\n",
      "1. Data Collection: Data scientists collect data from various sources such as databases, websites, sensors, and more.\n",
      "\n",
      "2. Data Cleaning: Data cleaning involves removing errors, inconsistencies, and missing values from the data to ensure its quality and reliability.\n",
      "\n",
      "3. Data Exploration: Data exploration involves analyzing and visualizing the data to understand its patterns, trends, and relationships.\n",
      "\n",
      "4. Statistical Analysis: Data scientists use statistical methods to analyze the data and draw meaningful insights from it.\n",
      "\n",
      "5. Machine Learning: Machine learning is a subset of data science that involves building models and algorithms that can learn from data and make predictions or decisions.\n",
      "\n",
      "6. Data Visualization: Data visualization is the process of presenting data in visual formats such as charts, graphs, and dashboards to communicate insights effectively.\n",
      "\n",
      "7. Data Interpretation: Data scientists interpret the results of their analysis to draw conclusions and make data-driven decisions.\n",
      "\n",
      "8. Communication: Data scientists need to effectively communicate their findings to stakeholders, including non-technical audiences.\n",
      "\n",
      "These are just some of the basics of data science, and the field is constantly evolving with new techniques and technologies.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([\n",
    "    SystemMessage(content= \"You are a Data Science teacher\"),\n",
    "    HumanMessage(content= 'Please tell me the basics of data science')\n",
    "])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65907ea",
   "metadata": {},
   "source": [
    "## Propmt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f6e65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseparatedoutput(StrOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1faf6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant. When the user gives any input, you should generate five words synonyms which should be comma separated\"\n",
    "human_template = \"{text}\"\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b94b6d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = chat_prompt | llm | Commaseparatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad941308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' astute', ' sharp']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chains.invoke({\"text\": \"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116338d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
