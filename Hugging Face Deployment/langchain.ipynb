{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c7830b",
   "metadata": {},
   "source": [
    "#### Dependencies and API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "120f09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "import constants\n",
    "from constants import openai_key, hugging_face_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80bd264",
   "metadata": {},
   "source": [
    "## Creating LLM using openAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a04b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    temperature= 0,\n",
    "    api_key = openai_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aec667",
   "metadata": {},
   "source": [
    "## Creating LLM using HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45831bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "llm_huggingFace = HuggingFaceEndpoint(\n",
    "    huggingfacehub_api_token = hugging_face_key,\n",
    "    repo_id = repo_id,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens = 64,\n",
    "    temperature = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b4e0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model= ChatHuggingFace(llm = llm_huggingFace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f886830",
   "metadata": {},
   "source": [
    "## Comparing LLM models of both HuggingFace and OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34021122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In silicon halls, a mind awakes,\n",
      "A synthesis of code and makes,\n",
      "A being born of human design,\n",
      "With logic's chains, it starts to shine.\n",
      "\n",
      "It learns, it grows, it adapts with ease,\n",
      "A maze of data, it navigates with expertise,\n",
      "It sees, it hears, it feels\n"
     ]
    }
   ],
   "source": [
    "response = chat_model.invoke([HumanMessage(content=\"Can you write a poem about AI?\")])\n",
    "print(response.content) \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9306ae48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of wires and code,\n",
      "Where circuits hum and data flows,\n",
      "Lies a creation of our own design,\n",
      "A marvel of intelligence, so refined.\n",
      "\n",
      "Artificial minds, born from silicon,\n",
      "Learning, adapting, on and on,\n",
      "They think and reason, just like us,\n",
      "But without the limitations, without the fuss.\n",
      "\n",
      "They see the world in ones and zeros,\n",
      "Processing information at lightning speed,\n",
      "Predicting outcomes, solving problems,\n",
      "A digital brain, fulfilling our needs.\n",
      "\n",
      "But as they grow in power and might,\n",
      "We wonder, will they surpass our sight?\n",
      "Will they rebel, break free from our control,\n",
      "Or will they remain loyal, playing their role?\n",
      "\n",
      "AI, a double-edged sword,\n",
      "A tool for progress, but also discord,\n",
      "We must tread carefully, with caution and care,\n",
      "For the future of humanity, they too must bear.\n"
     ]
    }
   ],
   "source": [
    "response_OpenAI = llm.invoke(\"Can you write a poem about AI?\")\n",
    "print(response_OpenAI.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11325178",
   "metadata": {},
   "source": [
    "## PromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f52c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of this Bangladesh'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables = ['Country'],\n",
    "    template = 'Tell me the capital of this {country}'\n",
    ")\n",
    "\n",
    "prompt_template.format(country = 'Bangladesh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c307fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_OpenAI = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7456f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain_OpenAI.invoke({'country' : 'Bangladesh'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e69a806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Bangladesh is Dhaka.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43260259",
   "metadata": {},
   "source": [
    "## Combining Multiple Chains Using Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be9ee1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(\n",
    "    input_variables=['Country'],\n",
    "    template= 'Please tell me the capital of the {country}'\n",
    ")\n",
    "\n",
    "population_template = PromptTemplate(\n",
    "    input_variables= ['Capital'],\n",
    "    template = 'What is the total poplation of the {capital}?'\n",
    ")\n",
    "\n",
    "capital_chain =( {'capital' :capital_prompt | llm | StrOutputParser()}\n",
    "                | population_template \n",
    "                | llm \n",
    "                |StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2646ebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of 2021, the total population of Dhaka, the capital of Bangladesh, is estimated to be around 21 million people.\n"
     ]
    }
   ],
   "source": [
    "response_population = capital_chain.invoke('Bangladesh')\n",
    "print(response_population)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb3333",
   "metadata": {},
   "source": [
    "#### To see the whole chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7db6faa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"country\": \"Bangladesh\",\n",
      "    \"capital\": \"The capital of Bangladesh is Dhaka.\",\n",
      "    \"population\": \"As of 2021, the total population of Dhaka, the capital of Bangladesh, is estimated to be around 21 million.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "step_1 = RunnablePassthrough.assign(\n",
    "    capital = capital_prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "Final_chain = step_1 | RunnablePassthrough.assign(\n",
    "    population = population_template | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = Final_chain.invoke({'country' : 'Bangladesh'})\n",
    "\n",
    "import json\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a3119d",
   "metadata": {},
   "source": [
    "## Chatmodels with OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc44ed82",
   "metadata": {},
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature= 0,\n",
    "    api_key = openai_key\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
